{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.a) Making list of all labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(directory):\n",
    "    Labels = []\n",
    "    \n",
    "    for labels in os.listdir(directory):\n",
    "        Labels.append(labels)\n",
    "        \n",
    "    return Labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "allLabels = get_labels('data/flowers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'flowers', 'rose', 'sunflower', 'tulip']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b) Making list of images and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(directory):\n",
    "    Images = []\n",
    "    Labels = []\n",
    "    \n",
    "    for labels in os.listdir(directory):\n",
    "        label = allLabels.index(labels)\n",
    "        \n",
    "        for image_file in os.listdir(directory+labels):\n",
    "            image = cv2.imread(directory+labels+r'/'+image_file)\n",
    "            if image is not None:\n",
    "                image = cv2.resize(image,(250,250))\n",
    "                \n",
    "                Images.append(image)\n",
    "                Labels.append(label)\n",
    "            else:\n",
    "                print(directory+labels+r'/'+image_file)\n",
    "            \n",
    "            \n",
    "    return shuffle(Images,Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\daisycharlie\\Anaconda3\\envs\\tensor2_real\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-be123e00a2f4>\", line 1, in <module>\n",
      "    Images,Labels = get_images('../input/flowers-recognition/flowers/flowers/')\n",
      "  File \"<ipython-input-26-fb77b4b2d0b5>\", line 5, in get_images\n",
      "    for labels in os.listdir(directory):\n",
      "FileNotFoundError: [WinError 3] The system cannot find the path specified: '../input/flowers-recognition/flowers/flowers/'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\daisycharlie\\Anaconda3\\envs\\tensor2_real\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\daisycharlie\\Anaconda3\\envs\\tensor2_real\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\daisycharlie\\Anaconda3\\envs\\tensor2_real\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\daisycharlie\\Anaconda3\\envs\\tensor2_real\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\daisycharlie\\Anaconda3\\envs\\tensor2_real\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\daisycharlie\\Anaconda3\\envs\\tensor2_real\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\daisycharlie\\Anaconda3\\envs\\tensor2_real\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\daisycharlie\\Anaconda3\\envs\\tensor2_real\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\daisycharlie\\Anaconda3\\envs\\tensor2_real\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\daisycharlie\\Anaconda3\\envs\\tensor2_real\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\daisycharlie\\Anaconda3\\envs\\tensor2_real\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\daisycharlie\\Anaconda3\\envs\\tensor2_real\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 43, in <module>\n",
      "    from . _api.v2 import autodiff\n",
      "ImportError: cannot import name 'autodiff' from 'tensorflow_core._api.v2' (C:\\Users\\daisycharlie\\Anaconda3\\envs\\tensor2_real\\lib\\site-packages\\tensorflow_core\\_api\\v2\\__init__.py)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input/flowers-recognition/flowers/flowers/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "Images,Labels = get_images('../input/flowers-recognition/flowers/flowers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = Images\n",
    "bl = Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = bi\n",
    "Labels = bl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting images to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = np.array(Images)\n",
    "Labels = np.array(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.c) Image Preprocessing for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert images to grayscal\n",
    "Images = np.sum(Images/3,axis=3,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Images[0].squeeze(),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize images\n",
    "Images = Images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Splitting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test and train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_valid,y_train,y_valid = train_test_split(Images,Labels,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,\n",
    "#                                                test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Creating a CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = (input-filter +1)/stride\n",
    "model = Sequential()\n",
    "#1st convolutional layer\n",
    "model.add(Conv2D(filters=64,kernel_size=(5,5),padding='same',activation='relu',input_shape=(150,150,3)))#(150-5+1)/1\n",
    "model.add(MaxPool2D())#output = 73\n",
    "model.add(BatchNormalization())#o = 73\n",
    "model.add(Dropout(0.2))#o = 73\n",
    "\n",
    "#2nd convolutional layer\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),padding='same',activation='relu'))#(73-3+1)/1\n",
    "model.add(MaxPool2D(strides=(2,2)))#output = 35\n",
    "model.add(BatchNormalization())#o = 35\n",
    "model.add(Dropout(0.2))#o = 35\n",
    "\n",
    "#3rd convolutional layer\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),padding='same',activation='relu'))#(35-3+1)/1\n",
    "model.add(MaxPool2D(strides=(2,2)))#output = 16\n",
    "model.add(BatchNormalization())#o = 16\n",
    "model.add(Dropout(0.2))#o = 16\n",
    "model.summary()\n",
    "\n",
    "#4th convolutional layer\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),padding='same',activation='relu'))#(16-3+1)/1\n",
    "model.add(MaxPool2D(strides=(2,2)))#output = 16\n",
    "model.add(BatchNormalization())#o = 16\n",
    "model.add(Dropout(0.2))#o = 16\n",
    "model.summary()\n",
    "\n",
    "#5th convolutional layer\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),padding='same',activation='relu'))#(16-3+1)/1\n",
    "model.add(MaxPool2D(strides=(2,2)))#output = 16\n",
    "model.add(BatchNormalization())#o = 16\n",
    "model.add(Dropout(0.2))#o = 16\n",
    "\n",
    "#6th convolutional layer\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),padding='same',activation='relu'))#(16-3+1)/1\n",
    "model.add(MaxPool2D(strides=(2,2)))#output = 16\n",
    "model.add(BatchNormalization())#o = 16\n",
    "model.add(Dropout(0.2))#o = 16\n",
    "\n",
    "model.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "model.add(Dense(1024,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1024,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add output layer\n",
    "model.add(Dense(5,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(x_train,y_train,epochs=50,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2766/86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historyd = model.fit_generator(train_datagen.flow(x_train,y_train,batch_size=32),epochs=100,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. no scaling etc output - 55-60\n",
    "2. added another set of dense layer neuron - accuracy slightly increase to 62\n",
    "3. added parameter padding='same' to each conv layer - not much differrence\n",
    "4. increasing kernels and adding dense layers - accuracy remained roughly same , resulted in overfitting\n",
    "5. chenging learning rate-accuracy reduced\n",
    "6. increased image size to 256-accuracy reduced\n",
    "7. added another conv layer with increased size - accuracy reduced\n",
    "8. sent input data in rgb format instead of grayscale - accuracy increases\n",
    "9. following operations were applied - gave better results\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "10. adding batch size and increaseing epochs to 80 - ccuracy between 65 and 75\n",
    "11. adding more data to training set and increasing epochs to 100 - accuracy increased to 80%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------- with transfer learning ----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resetting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = bi\n",
    "Labels = bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = np.array(Images)\n",
    "Labels = np.array(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = Images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "Labels = keras.utils.to_categorical(Labels,num_classes=5,dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(Images,Labels,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(Images,Labels,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_valid,y_train,y_valid = train_test_split(x_train,y_train,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "base_model = VGG16(weights='imagenet',include_top=False,input_shape=(250,250,3))\n",
    "#base_model = MobileNetV2(input_shape=(150,150,3),weights='imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024,activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1024,activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(5,activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input,outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs = 50,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. after using base_model accuracy was reached in 10 epochs but it remained 60-65 on average\n",
    "2. dataset increased - validation accuracy still not going beyond 65\n",
    "3. categorical encoding done on labels - accuracy still not crossing 60\n",
    "4. reduced batch_size to 32 - no change\n",
    "5. trying Xception model - accuracy went till 70\n",
    "6. trying vgg 16 - ACCURACY WENT TILL 80 IN 15-20 EPOCHS\n",
    "7. trying vgg19 - slightly better than vgg 16\n",
    "8. trying resnet50-horrible\n",
    "9. trying resnet101-horrible\n",
    "10. InceptionResNetV2 - accuracy did not go beyond 70\n",
    "11. mobileNet - accuracy between 75-80\n",
    "12. MobileNetV2 - acc = 65-70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
